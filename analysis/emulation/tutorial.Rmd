---
title: "Pliocene_emulator"
author: "Jonnie Barnsley"
date: "2023-12-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Emulating BISICLES

This R notebook explores using the RobustGaSP R library to emulate the BISICLES ice sheet model. In this particular example, the BISICLES data has been produced by simulating Antarctica under a Pliocene climate. The experiment design included a Perturbed Parameter Ensemble, which perturbs 5 parameters in BISICLES:

 - gamma0 - a coefficient which controls ocean thermal forcing of ice shelves
 - UMV - the upper mantle viscosity
 - LRP - the precipitation lapse rate
 - PDDi - the Positive Degree Day factor for ice
 - WeertC - the Weertman friction coefficient
 
The output of the model is reduced to a single number = the sea level contribution from Antarctica after 10,000 years.

```{r libaries, message=FALSE}
library(dplyr) # dependency for RobustGaSP
library(RobustGaSP)
library(lhs)
```

### Part 1: Setting up the Emulator

```{r}
# import data
setwd("~/Code/phd/Emulation/Pliocene")
data <- read.csv('Pliocene data.csv')
ensemble <- na.omit(select(
  data,
  gamma0, 
  UMV, 
  LRP,
  PDDi,
  WeertC,
  main_minus_ctrle_10k
  ))
head(ensemble)
```

```{r}
# emulator design
inputs <- select(
  ensemble,
  gamma0,
  UMV,
  LRP,
  PDDi,
  WeertC
  )
# emulator response
output <- select(ensemble, main_minus_ctrle_10k)

pairs(inputs) # pairs plot
```

It can be helpful for emulators to define a trend. Otherwise known as the mean function, a trend tells the emulator about the expected relationship between the inputs and output. By default, the trend is zero (no relationship). We can incorporate knowledge of the underlying system into the emulator by defining a linear trend to which the emulator will converge in the absence of data. However, the emulator can and will diverge from the mean basis function if there is data in that part of the parameter space.

```{r}
trend <- as.matrix(cbind(1, inputs))

# create model
model <- rgasp(
  design = inputs, 
  response = output,
  nugget.est = TRUE, # nugget=TRUE accounts for factors not included in inputs (in this case, GCM)
  trend=trend
  )
```

### Part 2: Evaluating the Emulator

We can undertake a series of tests that investigate the performance of the emulator and some of its properties.

##### Inert Inputs

Inert inputs are inputs that do not evoke a statistically significant response in the output. Inert inputs are best dropped from the emulator, so it is worth checking to see if there are any in your emulator design.

```{r}
P <- findInertInputs(model)
```

##### Leave-One-Out Analysis

We want to test the accuracy of the emulator. We do this by removing a point from the inputs and asking the emulator to predict it. My "LeaveOneOut.R" script loads some custom functions for plotting these, including error bars and colouring according to whether the actual value is within the emulator uncertainty.

```{r, message=FALSE}
source("../LeaveOneOut.R")

loo <- leave_one_out(model) # will write a whole load of crap to the console which you can ignore
par(mfrow=c(1, 1)); plot.leave_one_out(loo)
```

##### Sensitivity Analysis

We want to test how sensitive the output is to each input and what relationship they have with sea level contribution.

```{r}
# Start by setting out limits of the parameter space
LB <- c(9620, 6e17, 0, 0.008, 7600)
UB <- c(471000, 1e21, 8e-4, 0.02, 62000)
range <- UB-LB
midpoints <- (LB+UB)/2

num.testpoints = 1000
# iterate over parameters
par(mfrow=c(2,3)); for (i in 1:5) {
  
  # generate a sensitivity.inputs matrix which takes a range of points for our
  # parameter and the midpoint value for every other parameter on every line
  plot_param <- as.matrix(seq(LB[i], UB[i], length.out=num.testpoints))
  sensitivity.inputs <- matrix(rep(midpoints, each = num.testpoints), nrow = num.testpoints)
  sensitivity.inputs[, i] <- plot_param
  
  # define testing trend in the same way as the design trend
  sensitivity.trend <- as.matrix(cbind(1, sensitivity.inputs))
  
  # emulate the output at each point
  sensitivity.predict <- predict(
    model,
    sensitivity.inputs,
    testing_trend=sensitivity.trend
  )
  
  # plot args
  xmin <- plot_param[1]
  xmax <- plot_param[num.testpoints]
  ymin <- min(sensitivity.predict$lower95)
  ymax <- max(sensitivity.predict$upper95)
  param <- colnames(inputs)[i]
  
  # make empty plot
  plot(1, 
       1,
       type='l',
       xlim=c(xmin, xmax),
       ylim=c(ymin, ymax),
       xlab=param,
       ylab='slc'
  )
  # shade 5-95% uncertainty region
  polygon(
    c(plot_param, rev(plot_param)), 
    c(sensitivity.predict$lower95, rev(sensitivity.predict$upper95)), 
    col='grey80', 
    border=F
    )
  # plot emulator mean
  lines(plot_param, sensitivity.predict$mean, type='l')
}
```

### Using the Emulator to predict BISICLES output

To demonstrate why emulation is so powerful for this use-case, let's take a look at what the BISICLES outputs alone tell us about sea level in the Pliocene.

```{r}
hist(
  ensemble$main_minus_ctrle_10k, 
  breaks=20, 
  xlim=c(-10, 25), 
  freq=F
  )
kde <- density(ensemble$main_minus_ctrle_10k)
lines(kde)
```

What a mess! A histogram of BISICLES outputs results in a rather block-y, gap-ridden probability distribution, which gives some vague information about Antarctic sea level contribution during the Pliocene, but lacks detail, especially on the tails of the distribution. Emulation gives us a chance to do what we could never do with BISICLES - run thousands of samples that investigate the parameter space in much greater detail and yield smoother probability distributions.

```{r}
# Latin Hypercube sample with 2000 samples from 5-D space
LHS <- maximinLHS(n=2000, k=5)

# re-scale the LHS to match the parameter space
for(i in 1:5) {
  LHS[,i] = LB[i] + range[i]*LHS[,i]
}

# define testing trend in the same way as design trend
testing_trend <- cbind(1, LHS)

# emulate the output at each point
model.predict <- predict(
  model, 
  LHS,
  testing_trend=testing_trend
  )

# kernel density estimate
kde <- density(model.predict$mean)

# plot histogram with kernel density estimate overlay
par(mfrow=c(1, 1))
hist(
  model.predict$mean, 
  xlim=c(-10, 25),
  breaks=25,
  freq=F
)
lines(kde, lwd=2, col='black')
```


